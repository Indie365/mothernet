{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from mothernet.datasets import load_openml_list, open_cc_valid_dids, open_cc_dids\n",
    "from mothernet.evaluation.baselines.tabular_baselines import knn_metric, catboost_metric, transformer_metric, logistic_metric, xgb_metric, random_forest_metric, mlp_metric\n",
    "from mothernet.evaluation.tabular_evaluation import evaluate, eval_on_datasets\n",
    "from mothernet.evaluation import tabular_metrics\n",
    "from mothernet.prediction.tabpfn import TabPFNClassifier\n",
    "from mothernet.evaluation.baselines import tabular_baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mothernet.datasets import load_openml_list, open_cc_dids, open_cc_valid_dids, test_dids_classification\n",
    "\n",
    "cc_valid_datasets_multiclass, cc_valid_datasets_multiclass_df = load_openml_list(open_cc_valid_dids, multiclass=True, shuffled=True, filter_for_nan=False, max_samples = 10000, num_feats=100, return_capped=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cc_valid_datasets_multiclass_df['NumberOfInstances'] =  cc_valid_datasets_multiclass_df['NumberOfInstances'].astype(int)\n",
    "cc_valid_datasets_multiclass_df['NumberOfFeatures'] =  cc_valid_datasets_multiclass_df['NumberOfFeatures'].astype(int)\n",
    "cc_valid_datasets_multiclass_df['NumberOfClasses'] =  cc_valid_datasets_multiclass_df['NumberOfClasses'].astype(int)\n",
    "\n",
    "print(cc_valid_datasets_multiclass_df[['did', 'name', 'NumberOfFeatures', 'NumberOfInstances', 'NumberOfClasses']].rename(columns={'NumberOfFeatures': \"d\", \"NumberOfInstances\":\"n\", \"NumberOfClasses\": \"k\"}).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setting params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "eval_positions = [1000]\n",
    "max_features = 100\n",
    "n_samples = 2000\n",
    "base_path = os.path.join('..')\n",
    "overwrite = False\n",
    "#max_times = [0.5, 1, 15, 30, 60, 60*5, 60*15, 60*60]\n",
    "#max_times = [1, 15]\n",
    "max_times = [1, 15, 30, 60, 60 * 5, 60 * 15, 60*60]\n",
    "metric_used = tabular_metrics.auc_metric\n",
    "task_type = 'multiclass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabpfn.evaluation.baselines.distill_mlp import DistilledTabPFNMLP\n",
    "from tabpfn.prediction.mothernet import PermutationsMeta, MotherNetClassifier\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline Evaluation\n",
    "This section runs baselines and saves results locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p {base_path}/results\n",
    "!mkdir -p {base_path}/results/tabular/\n",
    "!mkdir -p {base_path}/results/tabular/multiclass/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(cc_valid_datasets_multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_times = [1, 5, 15, 60, 5 * 60, 15 * 60, 60* 60]\n",
    "# these will all be evaluated on CPU because they are given as  callables, which is a weird way to do it.\n",
    "clf_dict= {\n",
    "    'knn': knn_metric,\n",
    "    'rf_new_params': random_forest_metric,\n",
    "    'xgb': xgb_metric,\n",
    "    'logistic': logistic_metric,\n",
    "    'mlp': mlp_metric}\n",
    "\n",
    "results_baselines = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_valid_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path)\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tabpfn.evaluation.tabular_evaluation import eval_on_datasets\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from tabpfn.prediction.mothernet import ShiftClassifier, EnsembleMeta, MotherNetClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# transformers don't have max times\n",
    "import warnings\n",
    "max_times = [1]\n",
    "device = \"cpu\"\n",
    "\n",
    "tabpfn_ours = TabPFNClassifier(device=device, model_string=\"tabpfn_nooptimizer_emsize_512_nlayers_12_steps_2048_bs_32ada_lr_0.0001_1_gpu_07_24_2023_01_43_33\", epoch=\"1650\", N_ensemble_configurations=3)\n",
    "mlp_distill = make_pipeline(StandardScaler(), DistilledTabPFNMLP(n_epochs=1000, device=device, hidden_size=128, n_layers=2, dropout_rate=.1, learning_rate=0.01, model_string=model_string, epoch=82, N_ensemble_configurations=3))\n",
    "mothernet_21_46_25_3940_ensemble3 = EnsembleMeta(MotherNetClassifier(path=\"mn_d2048_H4096_L2_W32_P512_1_gpu_warm_08_25_2023_21_46_25_epoch_3940_no_optimizer.pickle\", device=device), n_estimators=3)\n",
    "\n",
    "clf_dict= {\n",
    "    'mothernet': partial(transformer_metric, classifier=mothernet_21_46_25_3940_ensemble3, onehot=True),\n",
    "    'mlp_distill': mlp_distill,\n",
    "    'tabpfn': transformer_metric,\n",
    "    'tabpfn_ours': tabpfn_ours,\n",
    "    }\n",
    "results_transformers = [\n",
    "    eval_on_datasets('multiclass', model, model_name, cc_test_datasets_multiclass, eval_positions=eval_positions, max_times=max_times,\n",
    "                     metric_used=metric_used, split_numbers=[1, 2, 3, 4, 5],\n",
    "                     n_samples=n_samples, base_path=base_path, overwrite=False, n_jobs=-1, device=\"cuda\")\n",
    "    for model_name, model in clf_dict.items()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flat_results = []\n",
    "for per_dataset in results_baselines + results_transformers:\n",
    "    for result in per_dataset:\n",
    "        row = {}\n",
    "        for key in ['dataset', 'model', 'mean_metric', 'split', 'max_time']:\n",
    "            row[key] = result[key]\n",
    "        best_configs_key, = [k for k in result.keys() if \"best_configs\" in k]\n",
    "        if result[best_configs_key][0] is not None:\n",
    "            row.update(result[best_configs_key][0])\n",
    "        row['mean_metric'] = float(row[\"mean_metric\"].numpy())\n",
    "        flat_results.append(row)\n",
    "\n",
    "results_df = pd.DataFrame(flat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"results_validation.pickle\", \"wb\") as f:\n",
    "    pickle.dump(results_baselines + results_transformers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df.model.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df['model'] = results_df.model.replace({'knn': \"KNN\", 'rf_new_params': 'RF', 'mlp': \"MLP\",'mlp_distill': 'MLP-Distill', 'xgb':'XGBoost', 'logistic': 'LogReg',  'mothernet': 'MotherNet', 'tabpfn': 'TabPFN (Hollmann)', 'tabpfn_ours': 'TabPFN (ours)'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df.to_csv(\"results_validation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tabpfn_testing_environment]",
   "language": "python",
   "name": "conda-env-tabpfn_testing_environment-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
